name: quoridor-engine
version: "0.1"
author: James Harmon <JamesMHarmon@gmail.com>
about: AlphaZero in Rust
settings:
    - ArgRequiredElseHelp

subcommands:
    - init:
        about: Initializes a new run of a game.
        args:
            - game:
                required: true
                long: game
                short: g
                takes_value: true
                value_name: GAME NAME
                help: Name of the game to run.
            - run:
                required: true
                long: run
                short: r
                takes_value: true
                value_name: RUN NAME
                help: Name of the run, cannot contain '_'.
            - number_of_games_per_net:
                long: number_of_games_per_net
                takes_value: true
                help: "[Default: 32,000] The number of games to self play until a new net is generated. AZ used 5,000"
                value_name: SIZE
            - self_play_batch_size:
                long: self_play_batch_size
                takes_value: true
                help: "[Default: 256] The number of games to play in parallel during self play."
                value_name: SIZE
            - moving_window_size:
                long: moving_window_size
                takes_value: true
                help: "[Default: 500,000] How many games to go back and sample from when training a new net. AZ used 1,000,000."
                value_name: SIZE
            - position_sample_percentage:
                long: position_sample_percentage
                takes_value: true
                help: "[Default: 0.7] What percentage of positions to be sampled from each game. AZ training_steps 700e3 / window 1e6 = 0.70% of positions were used per training run."
                value_name: PERCENTAGE
            - train_ratio:
                long: train_ratio
                takes_value: true
                help: "[Default: 0.9] The ratio of training to test data when training a new net."
                value_name: RATIO
            - train_batch_size:
                long: train_batch_size
                takes_value: true
                help: "[Default: 512] The batch size of sample games to provide a net during training."
                value_name: SIZE
            - epochs:
                long: epochs
                takes_value: true
                help: "[Default: 1] The number of epochs to use when training a net."
                value_name: EPOCHS
            - learning_rate:
                long: learning_rate
                takes_value: true
                help: "[Default: 0.2] The learning rate to use when training a net. AZ used the following schedule 0: 2e-1, 100e3: 2e-2, 300e3: 2e-3, 500e3: 2e-4"
                value_name: RATE
            - policy_loss_weight:
                long: policy_loss_weight
                takes_value: true
                help: "[Default: 1.0] The weight of the policy loss to apply compared to the value loss."
                value_name: LOSS
            - value_loss_weight:
                long: value_loss_weight
                takes_value: true
                help: "[Default: 0.5] The weight of the value loss to apply compared to the policy loss."
                value_name: LOSS
            - temperature:
                long: temperature
                takes_value: true
                help: "[Default: 1.0] The temperature to use during self play games before the temperature_max_actions threshold has been met. The higher the temp, the more exploration."
                value_name: TEMP
            - temperature_max_actions:
                long: temperature_max_actions
                takes_value: true
                help: "[Default: 30] The number of actions in the game to be made before changing the temperature to temperature_post_max_actions."
                value_name: NUM
            - temperature_post_max_actions:
                long: temperature_post_max_actions
                takes_value: true
                help: "[Default: 0.45] The temperature to use during self play games after the temperature_max_actions threshold has been met. The higher the temp, the more exploration."
                value_name: TEMP
            - visits:
                long: visits
                takes_value: true
                help: "[Default: 800] The number of visits of the root node as part of the mcts before deciding on a move to take. AZ used 800"
                value_name: VISITS
            - cpuct_base:
                long: cpuct_base
                takes_value: true
                help: "[Default: 19,652] Adds a scaling factor for cpuct, the more visits that a node has, the more that exploration over exploitation will be favored. AZ used 19,652"
                value_name: NUM
            - cpuct_init:
                long: cpuct_init
                takes_value: true
                help: "[Default: 1.25] The cpuct value within the MCTS algorithm. A higher cpuct encourages exploration over exploitation. AZ used 1.25"
                value_name: NUM
            - alpha:
                long: alpha
                takes_value: true
                help: "[Default: 0.3] The alpha value within the MCTS algorithm specific to Dirichlet noise. AZ used 0.3"
                value_name: NUM
            - epsilon:
                long: epsilon
                takes_value: true
                help: "[Default: 0.25] The epsilon value within the MCTS algorithm specific to Dirichlet noise. AZ used 0.25"
                value_name: NUM
            - number_of_filters:
                long: number_of_filters
                takes_value: true
                help: "[Default: 64] The number of number of filters to use within a convolution layer as part of the net."
                value_name: NUM
            - number_of_residual_blocks:
                long: number_of_residual_blocks
                takes_value: true
                help: "[Default: 5] The number of residual blocks to use as part of the net."
                value_name: NUM
    - run:
        about: Continues on an existing run.
        args:
            - game:
                required: true
                short: g
                long: game
                takes_value: true
                value_name: GAME NAME
                help: Name of the game to run.
            - run:
                required: true
                short: r
                long: run
                takes_value: true
                value_name: RUN NAME
                help: Name of the run, cannot contain '_'.